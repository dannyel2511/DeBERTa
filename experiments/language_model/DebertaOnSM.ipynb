{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ed935d",
   "metadata": {},
   "source": [
    "# Use SageMaker Distributed Data Parallel library to pre-train DeBERTa v3\n",
    "\n",
    "[Amazon SageMaker's distributed library](https://docs.aws.amazon.com/sagemaker/latest/dg/distributed-training.html) can be used to train deep learning models faster and cheaper. The [data parallel](https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel.html) feature in this library (`smdistributed.dataparallel`) is a distributed data parallel training framework that provides seamless integration with common frameworks, like PyTorch and TensorFlow.\n",
    "\n",
    "This notebook example shows how to use SageMaker's DDP (SMDDP) library with PyTorch(version 1.10.2) on [Amazon SageMaker](https://aws.amazon.com/sagemaker/) to pre-train DeBERTa v3 using the public available wiki103 dataset. Note that this notebook showcases an example to use MLM.\n",
    "\n",
    "\n",
    "The outline of steps is as follows:\n",
    "\n",
    "1. Stage dataset in [Amazon S3](https://aws.amazon.com/s3/).\n",
    "2. Configure the estimator function options, like distribution strategy and hyperparameters.\n",
    "3. Use PyTorch estimator to pre-train DeBERTa v3 on wiki103 dataset.\n",
    "\n",
    "**NOTE:** This example requires SageMaker Python SDK v2.X. and PyTorch >= 1.10.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e2968e",
   "metadata": {},
   "source": [
    "## Amazon SageMaker Initialization\n",
    "\n",
    "Initialize the notebook instance. Get the AWS Region and a SageMaker execution role.\n",
    "\n",
    "### SageMaker role\n",
    "\n",
    "The following code cell defines `role` which is the IAM role ARN used to create and run SageMaker training and hosting jobs. This is the same IAM role used to create this SageMaker Notebook instance. \n",
    "\n",
    "`role` must have permission to create a SageMaker training job and host a model. For granular policies you can use to grant these permissions, see [Amazon SageMaker Roles](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html). If you do not require fine-tuned permissions for this demo, you can use the IAM managed policy AmazonSageMakerFullAccess to complete this demo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.local import LocalSession\n",
    "import boto3\n",
    "\n",
    "local_mode = False\n",
    "\n",
    "role = (\n",
    "    get_execution_role() # Provide a pre-existing role ARN as an alternative to creating a new role\n",
    ")  \n",
    "print(f\"SageMaker Execution Role: {role}\")\n",
    "\n",
    "client = boto3.client(\"sts\")\n",
    "account = client.get_caller_identity()[\"Account\"]\n",
    "print(f\"AWS account: {account}\")\n",
    "if local_mode:\n",
    "    session = LocalSession()\n",
    "    session.config = {'local': {'local_code': True}}\n",
    "    sagemaker_session = session\n",
    "    region = 'us-west-2' # Update to appropiate region.\n",
    "else:\n",
    "    session = boto3.session.Session()\n",
    "    region = session.region_name\n",
    "    print(f\"AWS region: {region}\")\n",
    "    sm_boto_client = boto3.client(\"sagemaker\")\n",
    "    sagemaker_session = sagemaker.session.Session(boto_session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b2915c",
   "metadata": {},
   "source": [
    "### Configure paths to dataset using Amazon S3 bucket\n",
    "In this step we configure the data channels to point to the dataset from an Amazon S3 bucket.\n",
    "\n",
    "Modify the cell bellow to point to the correct path where your dataset is hosted. If you are using wiki103, make sure that the data is already tokenized by previously running the script _prepare_data.py_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4125028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default bucket\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "print(\"Default bucket for this session: \", default_bucket)\n",
    "\n",
    "# Set the location for this training job. This path must contain the dataset and will be used to save the checkpoints.\n",
    "bucket_uri = f\"s3://{default_bucket}/deberta-v3\"\n",
    "# Set location to training data\n",
    "train_data_location = f\"{bucket_uri}/data/\"\n",
    "# Configure data channels for SM training job.\n",
    "train = sagemaker.inputs.TrainingInput(train_data_location, distribution=\"FullyReplicated\", s3_data_type=\"S3Prefix\")\n",
    "data_channels = {\"train\": train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdb4c79",
   "metadata": {},
   "source": [
    "### Configure SageMaker PyTorch Estimator function options\n",
    "\n",
    "In the following code blocks, you can update the estimator function to use a different instance type, instance count, distribution strategy and hyperparameters. You're also passing an entry point to the training script.\n",
    "\n",
    "**Instance types**\n",
    "\n",
    "`smdistributed.dataparallel` supports model training on SageMaker with the following instance types only. For best performance, it is recommended you use an instance type that supports [Amazon Elastic Fabric Adapter (EFA)](https://aws.amazon.com/hpc/efa/).\n",
    "\n",
    "1. `ml.p3.16xlarge`\n",
    "1. `ml.p3dn.24xlarge` [Recommended]\n",
    "1. `ml.p4d.24xlarge` [Recommended]\n",
    "\n",
    "**Instance count**\n",
    "\n",
    "To get the best performance and the most out of `smdistributed.dataparallel`, you should use at least 2 instances, but you can also use 1 for testing this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = \"ml.p4d.24xlarge\"\n",
    "instance_count = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ff7b6c",
   "metadata": {},
   "source": [
    "**Distribution strategy**\n",
    "\n",
    "Note that to use DDP mode, you need to update the `distribution` strategy, and set it to use `smdistributed dataparallel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adbe745",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_strategy = {\"smdistributed\": {\"dataparallel\": {\"enabled\": True}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138306a3",
   "metadata": {},
   "source": [
    "**Assign a base name**\n",
    "\n",
    "The base name is used as prefix to the SageMaker training job, so you can identify it easily in the [SageMaker console](console.aws.amazon.com/sagemaker/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dfb616",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_job_name = \"deberta-v3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8828e4",
   "metadata": {},
   "source": [
    "**Create the estimator function and pass the parameters**\n",
    "\n",
    "Use all parameters from previous sections to configure the estimator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38137d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "import os\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point='launcher_ddp.py', \n",
    "    source_dir=os.path.dirname(os.path.dirname(os.getcwd())),\n",
    "    role=role,\n",
    "    instance_type=instance_type if not local_mode else 'local_gpu',\n",
    "    volume_size=500,\n",
    "    instance_count=instance_count,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    distribution=distribution_strategy,\n",
    "    framework_version=\"1.10\",\n",
    "    py_version=\"py38\",\n",
    "    output_path=f\"{bucket_uri}/output/\",\n",
    "    checkpoint_s3_uri=f\"{bucket_uri}/experiments/{base_job_name}/\",\n",
    "    checkpoint_local_path='/opt/ml/checkpoints/',\n",
    "    debugger_hook_config=False,\n",
    "    disable_profiler=True,\n",
    "    base_job_name=base_job_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef33fb",
   "metadata": {},
   "source": [
    "## Start the SageMaker training job\n",
    "Run the cell below to start the pre-training of DeBERTa v3 on wiki103 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c770dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5845be94",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "To avoid incurring unnecessary charges, follow these [steps to use the AWS Management Console to delete resources such as endpoints, notebook instances, S3 buckets, and CloudWatch logs](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-cleanup.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
